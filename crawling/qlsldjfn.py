import requests
from bs4 import BeautifulSoup
import json

# ì €ì¥ë˜ëŠ” json íŒŒì¼ ì´ë¦„
file_name = "../school_inf.json"

# ê¸°ë³¸ URL
BASE_URL = "https://plus.cnu.ac.kr/_prog/_board/"

# ìš”ì²­ íŒŒë¼ë¯¸í„°
PARAMS = {
    "code": "sub07_0702",
    "site_dvs_cd": "kr",
    "menu_dvs_cd": "0702",
    "skey": "",
    "sval": "",
    "site_dvs": "",
    "ntt_tag": "",
    "GotoPage": 1
}

def get_notice_list(page=1):
    PARAMS["GotoPage"] = page
    response = requests.get(BASE_URL, params=PARAMS)
    response.encoding = 'utf-8'
    soup = BeautifulSoup(response.text, 'html.parser')

    # board_list í´ë˜ìŠ¤ì˜ div ê°ì²´ ì°¾ê¸°
    board_div = soup.find('div', class_='board_list')
    if not board_div:
        print("ğŸ“› 'board_list' í´ë˜ìŠ¤ë¥¼ ê°€ì§„ divë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        return []

    rows = board_div.find_all('tr')
    notices = []

    for row in rows[1:]:  # ì²« ë²ˆì§¸ëŠ” í—¤ë”
        cols = row.find_all('td')
        if len(cols) < 4:
            continue

        title_tag = cols[1].find('a')
        if not title_tag:
            continue

        title = title_tag.get_text(strip=True)

        # ì‘ì„±ì
        writer = cols[2].get_text(strip=True)

        # ë‚ ì§œ
        date = cols[3].get_text(strip=True)

        notices.append({
            'title': title,
            'writer': writer,
            'date': date
        })

    return notices

all_notices = []
for page in range(1, 6):  # ì˜ˆ: 5í˜ì´ì§€ê¹Œì§€ í¬ë¡¤ë§
    notices = get_notice_list(page)
    if not notices:
        break
    all_notices.extend(notices)

print(f"ì´ {len(all_notices)}ê°œì˜ ê²Œì‹œë¬¼ ìˆ˜ì§‘ ì™„ë£Œ")

for d in all_notices:
    print(d)

with open(file_name, "w", encoding="utf-8") as f:
    json.dump(all_notices, f, ensure_ascii=False, indent=2)