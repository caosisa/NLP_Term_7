#!/usr/bin/env python3
# -*- coding: utf-8 -*-
import json
import os
import re
import requests
from datetime import datetime, date
import calendar
from bs4 import BeautifulSoup
from transformers import AutoTokenizer, AutoModelForCausalLM
import torch
import torch.nn as nn
from tqdm import tqdm
import time
import os

# í™˜ê²½ë³€ìˆ˜ë¡œ ì„¤ì •
os.environ["CUDA_VISIBLE_DEVICES"] = "0"  # GPU 1ë²ˆë§Œ ì‚¬ìš©

class CompleteCampusKnowledgeBase:
    """ì™„ì „í•œ ìº í¼ìŠ¤ ì§€ì‹ ë² ì´ìŠ¤ (ì •ì  + ì‹¤ì‹œê°„)"""

    def __init__(self):
        self.setup_static_knowledge()
        self.setup_real_urls()
        self.cache = {}
        self.cache_timeout = 1800  # 30ë¶„ ìºì‹œ

    def setup_static_knowledge(self):
        """ì •ì  ì§€ì‹ (í•­ìƒ ì •í™•í•œ ê¸°ë³¸ ì •ë³´)"""
        self.static_knowledge = {
            "graduation": {
                "general": "ì¶©ë‚¨ëŒ€í•™êµ ì¼ë°˜ì ì¸ ì¡¸ì—…ìš”ê±´ì€ 130í•™ì  ì´ìƒì…ë‹ˆë‹¤.",
                "engineering": "ê³µí•™ê³„ì—´ì€ 140í•™ì  ì´ìƒì´ í•„ìš”í•©ë‹ˆë‹¤.",
                "composition": "ì „ê³µí•„ìˆ˜ + ì „ê³µì„ íƒ + êµì–‘í•„ìˆ˜ + êµì–‘ì„ íƒ + ì¼ë°˜ì„ íƒìœ¼ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤.",
                "major_required": "ì „ê³µí•„ìˆ˜ëŠ” í•™ê³¼ë³„ ì§€ì • ê³¼ëª©ì„ ëª¨ë‘ ì´ìˆ˜í•´ì•¼ í•©ë‹ˆë‹¤.",
                "major_elective": "ì „ê³µì„ íƒì€ í•™ê³¼ë³„ ìµœì†Œ ì´ìˆ˜ í•™ì ì„ ì¶©ì¡±í•´ì•¼ í•©ë‹ˆë‹¤.",
                "general_education": "êµì–‘ì€ ê¸°ì´ˆêµì–‘(ì˜ì–´, ì»´í“¨í„°, ì²´ìœ¡)ê³¼ ê· í˜•êµì–‘(ì¸ë¬¸, ì‚¬íšŒ, ìì—°)ìœ¼ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤.",
                "double_major": "ë³µìˆ˜ì „ê³µì€ ì£¼ì „ê³µ + ë³µìˆ˜ì „ê³µ ê° 36í•™ì  ì´ìƒ í•„ìš”í•©ë‹ˆë‹¤.",
                "contact": "ì •í™•í•œ ì¡¸ì—…ìš”ê±´ì€ ì†Œì† í•™ê³¼ ì‚¬ë¬´ì‹¤ì´ë‚˜ í•™ì‚¬ì§€ì›ê³¼(042-821-5025)ì— ë¬¸ì˜í•˜ì„¸ìš”."
            },

            "academic_schedule": {
                "course_registration": "ìˆ˜ê°•ì‹ ì²­ ì¼ì •ì€ ë§¤ í•™ê¸° ì‹œì‘ ì „ì— í•™ì‚¬ì§€ì›ê³¼ì—ì„œ ê³µì§€í•©ë‹ˆë‹¤.",
                "system": "CNU í¬í„¸ì‹œìŠ¤í…œ(portal.cnu.ac.kr)ì—ì„œ ì§„í–‰ë©ë‹ˆë‹¤.",
                "correction": "ìˆ˜ê°•ì •ì •ì€ ê°œê°• í›„ 1ì£¼ì¼ ë™ì•ˆ ê°€ëŠ¥í•©ë‹ˆë‹¤.",
                "midterm": "ì¤‘ê°„ê³ ì‚¬ëŠ” ë³´í†µ 4ì›”(1í•™ê¸°), 10ì›”(2í•™ê¸°) ì¤‘ìˆœê²½ì…ë‹ˆë‹¤.",
                "final": "ê¸°ë§ê³ ì‚¬ëŠ” ë³´í†µ 6ì›”(1í•™ê¸°), 12ì›”(2í•™ê¸°) ì¤‘ìˆœê²½ì…ë‹ˆë‹¤.",
                "semester_start": "1í•™ê¸°ëŠ” 3ì›”, 2í•™ê¸°ëŠ” 9ì›”ì— ì‹œì‘í•©ë‹ˆë‹¤.",
                "vacation": "ì—¬ë¦„ë°©í•™ì€ 6ì›”ë§~8ì›”ë§, ê²¨ìš¸ë°©í•™ì€ 12ì›”ë§~2ì›”ë§ì…ë‹ˆë‹¤.",
                "contact": "í•™ì‚¬ì§€ì›ê³¼(042-821-5025)ë¡œ ë¬¸ì˜í•˜ì„¸ìš”.",
                "website": "ì¶©ë‚¨ëŒ€ í™ˆí˜ì´ì§€(www.cnu.ac.kr)ì—ì„œ í™•ì¸ ê°€ëŠ¥í•©ë‹ˆë‹¤."
            },

            "dining": {
                "student_restaurant": {
                    "location": "í•™ìƒíšŒê´€ ì§€í•˜ 1ì¸µ",
                    "korean": "í•œì‹ 4,000ì›",
                    "western": "ì–‘ì‹ 5,000ì›",
                    "chinese": "ì¤‘ì‹ 5,500ì›",
                    "special": "íŠ¹ì‹ 6,000ì›"
                },
                "faculty_restaurant": {
                    "location": "í•™ìƒíšŒê´€ 2ì¸µ",
                    "price": "6,500-7,500ì›"
                },
                "cafeteria": {
                    "location": "ì •ì‹¬í™”êµ­ì œë¬¸í™”íšŒê´€ 1ì¸µ",
                    "menu": "ì¹´í˜, ê°„ì‹, ìƒëŸ¬ë“œ"
                },
                "hours": {
                    "breakfast": "08:00-09:30 (í‰ì¼, ì¼ë¶€ ì‹ë‹¹)",
                    "lunch": "11:30-14:00",
                    "dinner": "17:30-19:00"
                },
                "weekend": "ì£¼ë§ì—ëŠ” ëŒ€ë¶€ë¶„ ì‹ë‹¹ì´ ìš´ì˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.",
                "info_source": "ìƒí˜‘ í™ˆí˜ì´ì§€(coop.cnu.ac.kr)ì—ì„œ ì‹ë‹¨ì„ í™•ì¸í•˜ì„¸ìš”.",
                "contact": "ìƒí™œí˜‘ë™ì¡°í•©(042-821-5890)ìœ¼ë¡œ ë¬¸ì˜í•˜ì„¸ìš”."
            },

            "shuttle": {
                "operation_overview": {
                    "period": "2025. 3. 4.(í™”) ~ 2025. 12. 19.(ê¸ˆ), ì´ 150ì¼",
                    "location": "êµë‚´(ëŒ€ë•ìº í¼ìŠ¤) ë° ìº í¼ìŠ¤ ìˆœí™˜(ëŒ€ë•â†”ë³´ìš´)",
                    "buses": "í•™êµë²„ìŠ¤ ì´ 2ëŒ€, 41ì¸ìŠ¹",
                    "operation_days": "í•™ê¸° ì¤‘ ì£¼ê°„ ìš´ì˜(ì›”~ê¸ˆ)",
                    "non_operation": "ê³µíœ´ì¼Â·ëŒ€ì²´ê³µíœ´ì¼Â·ê°œêµê¸°ë…ì¼Â·ë°©í•™Â·ìˆ˜í•™ëŠ¥ë ¥ì‹œí—˜ì¼(10ì‹œ ì´ì „ê¹Œì§€) ë“± ë¯¸ìš´ì˜"
                },

                "campus_internal": {
                    "name": "êµë‚´ ìˆœí™˜ (ëŒ€ë•ìº í¼ìŠ¤ ë‚´)",
                    "operation_period": "í•™ê¸° ì¤‘ 3.4.ï½12.19. ì´ 150ì¼ (ì›”ï½ê¸ˆ)",
                    "buses": "1ëŒ€",
                    "frequency": "1ì¼ ì´ 10íšŒ ìš´ì˜",
                    "first_bus": "08:30",
                    "last_bus": "17:30",
                    "morning_special": "ë“±êµ 1íšŒì°¨: ì›”í‰ì—­ ì¶œë°œ 08:20 â†’ ì •ì‹¬í™” êµ­ì œë¬¸í™”íšŒê´€ ë„ì°©",
                    "schedule": [
                        "08:30", "09:30", "09:40", "10:30", "11:30",
                        "13:30", "14:30", "15:30", "16:30", "17:30"
                    ],

                    "route_stops": [
                        "ì •ì‹¬í™” êµ­ì œë¬¸í™”íšŒê´€", "ì‚¬íšŒê³¼í•™ëŒ€í•™ ì…êµ¬(í•œëˆ„ë¦¬íšŒê´€ ë’¤)",
                        "ì„œë¬¸(ê³µë™ì‹¤í—˜ì‹¤ìŠµê´€ ì•)", "ìŒì•… 2í˜¸ê´€ ì•", "ê³µë™ë™ë¬¼ì‹¤í—˜ì„¼í„°(íšŒì°¨)",
                        "ì²´ìœ¡ê´€ ì…êµ¬", "ì˜ˆìˆ ëŒ€í•™ ì•", "ë„ì„œê´€ ì•(ëŒ€í•™ë³¸ë¶€ ì˜†)", "í•™ìƒìƒí™œê´€ 3ê±°ë¦¬",
                        "ë†ì—…ìƒëª…ê³¼í•™ëŒ€í•™ ì•", "ë™ë¬¸ì£¼ì°¨ì¥"
                    ]
                },

                "campus_circulation": {
                    "name": "ìº í¼ìŠ¤ ìˆœí™˜ (ëŒ€ë•â†”ë³´ìš´)",
                    "operation_period": "í•™ê¸° ì¤‘ (ì›”ï½ê¸ˆ)",
                    "buses": "1ëŒ€",
                    "frequency": "1ì¼ ì´ 1íšŒ ìš´ì˜ (íšŒì°¨)",
                    "departure": "08:10 (ëŒ€ë• ê³¨í”„ì—°ìŠµì¥)",
                    "arrival": "08:50 (ë³´ìš´ìº í¼ìŠ¤)",
                    "route": "ê³¨í”„ì—°ìŠµì¥(08:10) â†’ ì¤‘ì•™ë„ì„œê´€(08:11) â†’ ì‚°í•™ì—°êµìœ¡ì—°êµ¬ê´€(08:12) â†’ ì¶©ë‚¨ëŒ€ì…êµ¬ ë²„ìŠ¤ì •ë¥˜ì¥(08:13) â†’ ì›”í‰ì—­(08:15) â†’ ë³´ìš´ìº í¼ìŠ¤(08:50)",
                    "return_route": "ë³´ìš´ìº í¼ìŠ¤ â†’ ë‹¤ì†”ì•„íŒŒíŠ¸ ê±´ë„ˆí¸ â†’ ì œ2í•™ìƒíšŒê´€ â†’ ì¤‘ì•™ë„ì„œê´€ â†’ ê³¨í”„ì—°ìŠµì¥"
                },

                "external_stops": {
                    "ì›”í‰ì—­": "3ë²ˆ ì¶œêµ¬ ê±´ë„ˆí¸(í…Œë‹ˆìŠ¤ì¥ ì• ë²„ìŠ¤ì •ë¥˜ì¥ ë¶€ê·¼)",
                    "ì¶©ë‚¨ëŒ€ì…êµ¬": "ë²„ìŠ¤ì •ë¥˜ì¥(í™ˆí”ŒëŸ¬ìŠ¤ìœ ì„±ì ë°©ë©´)",
                    "ë³´ìš´ìº í¼ìŠ¤": "íšŒì°¨ì§€ì ",
                    "ë‹¤ì†”ì•„íŒŒíŠ¸": "ê±´ë„ˆí¸"
                },

                "important_notes": [
                    "êµí†µìƒí™© ë“±ìœ¼ë¡œ ì¸í•´ ì „ êµ¬ê°„ì—ì„œ 5ë¶„ ë‚´ì™¸ ì˜¤ì°¨ ë°œìƒ ê°€ëŠ¥",
                    "íƒ‘ìŠ¹ìëŠ” ì‚¬ì „ ëŒ€ê¸° í•„ìš”",
                    "í•™êµ ë²„ìŠ¤ê°€ ë³´ì´ë©´ íƒ‘ìŠ¹ ì˜ì‚¬ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”",
                    "ìš´í–‰ì‹œê°„ì€ ì²œì¬ì§€ë³€, í•™êµí–‰ì‚¬, êµí†µìƒí™©, íƒ‘ìŠ¹ ì¸ì› ë“±ì— ë”°ë¼ ë³€ê²½ ê°€ëŠ¥",
                    "ì„¸ë¶€ ìš´í–‰ì‹œê°„ì€ ì´ìš©ì ë° ìš´í–‰ ì¶”ì´ì— ë”°ë¼ ë…¼ì˜ë¥¼ ê±°ì³ ë³€ë™ ê°€ëŠ¥"
                ],

                "contact": "ì´ë¬´ê³¼(042-821-5114) ë˜ëŠ” í•™ìƒì²˜ í•™ìƒê³¼",
                "last_updated": "2025. 2. 18.(í™”), í•™ìƒì²˜ í•™ìƒê³¼"
            },

            "notice": {
                "main_website": "ì¶©ë‚¨ëŒ€ í™ˆí˜ì´ì§€(www.cnu.ac.kr)ì—ì„œ í™•ì¸í•˜ì„¸ìš”.",
                "portal": "CNU í¬í„¸ì‹œìŠ¤í…œì—ì„œë„ ì¤‘ìš” ê³µì§€ë¥¼ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
                "department": "ê° í•™ê³¼ í™ˆí˜ì´ì§€ì—ì„œ í•™ê³¼ë³„ ê³µì§€ë¥¼ í™•ì¸í•˜ì„¸ìš”.",
                "scholarship": "ì¥í•™ê¸ˆ ê³µì§€ëŠ” í•™ìƒì§€ì›ê³¼ì—ì„œ ë‹´ë‹¹í•©ë‹ˆë‹¤.",
                "student_council": "ì´í•™ìƒíšŒ ê³µì§€ëŠ” ì´í•™ìƒíšŒ í™ˆí˜ì´ì§€ì—ì„œ í™•ì¸í•˜ì„¸ìš”.",
                "contacts": {
                    "í•™ì‚¬ì§€ì›ê³¼": "042-821-5025",
                    "í•™ìƒì§€ì›ê³¼": "042-821-5015"
                }
            },

            "contacts": {
                "í•™ì‚¬ì§€ì›ê³¼": "042-821-5025 (ì¡¸ì—…ìš”ê±´, í•™ì‚¬ì¼ì •)",
                "í•™ìƒì§€ì›ê³¼": "042-821-5015 (ì¥í•™ê¸ˆ, í•™ìƒí™œë™)",
                "ì´ë¬´ê³¼": "042-821-5114 (ì…”í‹€ë²„ìŠ¤, ì‹œì„¤)",
                "ìƒí™œí˜‘ë™ì¡°í•©": "042-821-5890 (ì‹ë‹¹, ë§¤ì )",
                "ë„ì„œê´€": "042-821-5092",
                "ì •ë³´í†µì‹ ì›": "042-821-6851"
            }
        }

    def setup_real_urls(self):
        """ì‹¤ì œ ì¶©ë‚¨ëŒ€ URLë“¤"""
        self.urls = {
            # ê³µì§€ì‚¬í•­
            "main_notice": "https://plus.cnu.ac.kr/",
            "academic_notice": "https://plus.cnu.ac.kr/_prog/_board/?code=sub07_0702&site_dvs_cd=kr&menu_dvs_cd=0702",
            "student_notice": "https://cnustudent.cnu.ac.kr/cnustudent/notice/notice.do",

            # í•™ì‚¬ì¼ì •
            "academic_calendar": "https://plus.cnu.ac.kr/_prog/academic_calendar/?site_dvs_cd=kr&menu_dvs_cd=05020101",

            # ì‹ë‹¨ ì •ë³´
            "meal_mobile": "https://mobileadmin.cnu.ac.kr/food/index.jsp",
            "dorm_meal": "https://dorm.cnu.ac.kr/",
            "coop_main": "https://www.cnucoop.co.kr/",

            # ì…”í‹€ë²„ìŠ¤
            "shuttle_info": "https://plus.cnu.ac.kr/html/kr/sub05/sub05_050403.html",
            "traffic_info": "https://plus.cnu.ac.kr/html/kr/sub01/sub01_01080302.html",
        }

    def get_cached_data(self, key):
        """ìºì‹œ ë°ì´í„° ì¡°íšŒ"""
        if key in self.cache:
            data, timestamp = self.cache[key]
            if time.time() - timestamp < self.cache_timeout:
                return data
        return None

    def set_cache(self, key, data):
        """ìºì‹œ ë°ì´í„° ì €ì¥"""
        self.cache[key] = (data, time.time())

    def safe_request(self, url, timeout=10):
        """ì•ˆì „í•œ ì›¹ ìš”ì²­"""
        try:
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
            }
            response = requests.get(url, headers=headers, timeout=timeout)
            response.raise_for_status()
            return response
        except Exception as e:
            print(f"âš ï¸ ì›¹ ìš”ì²­ ì‹¤íŒ¨ {url}: {e}")
            return None

    def fetch_today_menu(self):
        """ì˜¤ëŠ˜ì˜ ì‹ë‹¨ í¬ë¡¤ë§"""
        cached = self.get_cached_data("today_menu")
        if cached:
            return cached

        print("ğŸ½ï¸ ì‹ë‹¨ ì •ë³´ í¬ë¡¤ë§ ì¤‘...")

        try:
            # ì¶©ë‚¨ëŒ€ ëª¨ë°”ì¼ ì‹ë‹¨í‘œ í¬ë¡¤ë§ ì‹œë„
            response = self.safe_request(self.urls["meal_mobile"])

            if response and response.status_code == 200:
                soup = BeautifulSoup(response.text, 'html.parser')

                menu_data = {
                    "status": "í¬ë¡¤ë§ ì„±ê³µ",
                    "date": date.today().strftime("%Y-%m-%d"),
                    "day": ["ì›”", "í™”", "ìˆ˜", "ëª©", "ê¸ˆ", "í† ", "ì¼"][date.today().weekday()],
                    "source": "ì¶©ë‚¨ëŒ€ ëª¨ë°”ì¼ ì‹ë‹¨í‘œ",
                    "url": self.urls["meal_mobile"]
                }

                # í…ìŠ¤íŠ¸ì—ì„œ í•œêµ­ ìŒì‹ ì´ë¦„ ì¶”ì¶œ
                text = soup.get_text()
                korean_foods = re.findall(r'[ê°€-í£]+(?:êµ­|ì°Œê°œ|ë³¶ìŒ|êµ¬ì´|ì¡°ë¦¼|ë¬´ì¹¨|ë¹„ë¹”|íƒ•|ì£½|ë°¥)', text)

                if korean_foods:
                    menu_data["items"] = list(set(korean_foods[:10]))  # ì¤‘ë³µ ì œê±°, ìµœëŒ€ 10ê°œ
                    menu_data["message"] = f"ì˜¤ëŠ˜({menu_data['day']}ìš”ì¼) ì˜ˆìƒ ë©”ë‰´ì…ë‹ˆë‹¤."
                else:
                    menu_data["message"] = "ë©”ë‰´ ì •ë³´ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ì—ˆìŠµë‹ˆë‹¤."

                print("âœ… ì‹ë‹¨ í¬ë¡¤ë§ ì„±ê³µ")

            else:
                menu_data = {
                    "status": "í¬ë¡¤ë§ ì‹¤íŒ¨",
                    "date": date.today().strftime("%Y-%m-%d"),
                    "message": "ì‹ë‹¨í‘œ ì‚¬ì´íŠ¸ì— ì ‘ê·¼í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                    "fallback": "ê° ì‹ë‹¹ì—ì„œ ì§ì ‘ í™•ì¸í•˜ê±°ë‚˜ ìƒí˜‘ í™ˆí˜ì´ì§€ë¥¼ ì´ìš©í•˜ì„¸ìš”.",
                    "url": self.urls["meal_mobile"]
                }
                print("âš ï¸ ì‹ë‹¨ í¬ë¡¤ë§ ì‹¤íŒ¨")

            self.set_cache("today_menu", menu_data)
            return menu_data

        except Exception as e:
            print(f"âŒ ì‹ë‹¨ í¬ë¡¤ë§ ì˜¤ë¥˜: {e}")
            return {
                "status": "ì˜¤ë¥˜",
                "message": "ì‹ë‹¨ ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                "fallback": "ìƒí˜‘ í™ˆí˜ì´ì§€(coop.cnu.ac.kr)ì—ì„œ í™•ì¸í•˜ì„¸ìš”."
            }

    def fetch_latest_notices(self):
        """ìµœì‹  ê³µì§€ì‚¬í•­ í¬ë¡¤ë§"""
        cached = self.get_cached_data("notices")
        if cached:
            return cached

        print("ğŸ“¢ ê³µì§€ì‚¬í•­ í¬ë¡¤ë§ ì¤‘...")

        try:
            # ì¶©ë‚¨ëŒ€ ë©”ì¸ í˜ì´ì§€ í¬ë¡¤ë§
            response = self.safe_request(self.urls["main_notice"])

            notices = []

            if response and response.status_code == 200:
                soup = BeautifulSoup(response.text, 'html.parser')

                # ë‹¤ì–‘í•œ ì„ íƒìë¡œ ë‰´ìŠ¤/ê³µì§€ ì°¾ê¸°
                news_selectors = [
                    'h3', 'h4', 'h5',  # ì œëª© íƒœê·¸
                    '.news-title', '.notice-title', '.board-title',  # í´ë˜ìŠ¤ëª…
                    '[class*="title"]', '[class*="news"]',  # ë¶€ë¶„ í´ë˜ìŠ¤ëª…
                ]

                for selector in news_selectors:
                    elements = soup.select(selector)
                    for element in elements[:5]:  # ê° ì„ íƒìë‹¹ ìµœëŒ€ 5ê°œ
                        text = element.get_text(strip=True)
                        if text and len(text) > 10 and len(text) < 200:  # ì ì ˆí•œ ê¸¸ì´
                            notices.append({
                                "title": text,
                                "date": date.today().strftime("%Y-%m-%d"),
                                "source": "ì¶©ë‚¨ëŒ€ í™ˆí˜ì´ì§€",
                                "url": self.urls["main_notice"]
                            })

                    if len(notices) >= 3:  # ì¶©ë¶„íˆ ì°¾ì•˜ìœ¼ë©´ ì¤‘ë‹¨
                        break

                # ì¤‘ë³µ ì œê±°
                seen_titles = set()
                unique_notices = []
                for notice in notices:
                    if notice["title"] not in seen_titles:
                        seen_titles.add(notice["title"])
                        unique_notices.append(notice)
                        if len(unique_notices) >= 5:
                            break

                notices = unique_notices
                print(f"âœ… ê³µì§€ì‚¬í•­ {len(notices)}ê°œ í¬ë¡¤ë§ ì„±ê³µ")

            if not notices:
                notices = [{
                    "title": "ê³µì§€ì‚¬í•­ í¬ë¡¤ë§ ì‹¤íŒ¨",
                    "message": "ì¶©ë‚¨ëŒ€ í™ˆí˜ì´ì§€ì—ì„œ ì§ì ‘ í™•ì¸í•˜ì„¸ìš”.",
                    "url": self.urls["main_notice"],
                    "fallback": "ê° í•™ê³¼ í™ˆí˜ì´ì§€ë‚˜ CNU í¬í„¸ë„ í™•ì¸í•´ë³´ì„¸ìš”."
                }]
                print("âš ï¸ ê³µì§€ì‚¬í•­ í¬ë¡¤ë§ ì‹¤íŒ¨")

            self.set_cache("notices", notices)
            return notices

        except Exception as e:
            print(f"âŒ ê³µì§€ì‚¬í•­ í¬ë¡¤ë§ ì˜¤ë¥˜: {e}")
            return [{
                "title": "ê³µì§€ì‚¬í•­ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                "message": "ì¸í„°ë„· ì—°ê²°ì„ í™•ì¸í•˜ê³  ì¶©ë‚¨ëŒ€ í™ˆí˜ì´ì§€ë¥¼ ì§ì ‘ ë°©ë¬¸í•˜ì„¸ìš”.",
                "url": self.urls["main_notice"]
            }]

    def search_comprehensive_info(self, question):
        """í¬ê´„ì ì¸ ì •ë³´ ê²€ìƒ‰ (ì •ì  + ì‹¤ì‹œê°„)"""
        question_lower = question.lower()
        relevant_info = []

        # ì¡¸ì—…ìš”ê±´ ê´€ë ¨
        if any(word in question_lower for word in ['ì¡¸ì—…', 'í•™ì ', 'ì „ê³µ', 'êµì–‘', 'ìš”ê±´', 'ë…¼ë¬¸']):
            relevant_info.append(("ì¡¸ì—…ìš”ê±´_ì •ë³´", self.static_knowledge["graduation"]))

        # ê³µì§€ì‚¬í•­ ê´€ë ¨ (ì‹¤ì‹œê°„ í¬ë¡¤ë§)
        if any(word in question_lower for word in ['ê³µì§€', 'ì¥í•™ê¸ˆ', 'ì‹ ì²­', 'ì•ˆë‚´', 'ì†Œì‹', 'í–‰ì‚¬']):
            latest_notices = self.fetch_latest_notices()
            relevant_info.append(("ìµœì‹ ê³µì§€", latest_notices))
            relevant_info.append(("ê³µì§€ì‚¬í•­_ê¸°ë³¸ì •ë³´", self.static_knowledge["notice"]))

        # í•™ì‚¬ì¼ì • ê´€ë ¨
        if any(word in question_lower for word in
               ['ìˆ˜ê°•ì‹ ì²­', 'ìˆ˜ê°•', 'ì‹ ì²­', 'ì‹œí—˜', 'ê°œê°•', 'ì¢…ê°•', 'ì¼ì •', 'ì–¸ì œ', 'í•™ì‚¬', 'ë°©í•™', 'ê³„ì ˆí•™ê¸°']):
            relevant_info.append(("í•™ì‚¬ì¼ì •_ì •ë³´", self.static_knowledge["academic_schedule"]))

        # ì‹ë‹¨ ê´€ë ¨ (ì‹¤ì‹œê°„ í¬ë¡¤ë§)
        if any(word in question_lower for word in ['ì‹ë‹¨', 'í•™ì‹', 'ë©”ë‰´', 'ì‹ë‹¹', 'ë°¥', 'ì ì‹¬', 'ì €ë…', 'ì•„ì¹¨']):
            relevant_info.append(("ì‹ë‹¹_ê¸°ë³¸ì •ë³´", self.static_knowledge["dining"]))
            today_menu = self.fetch_today_menu()
            relevant_info.append(("ì˜¤ëŠ˜ë©”ë‰´", today_menu))

        # ì…”í‹€ë²„ìŠ¤ ê´€ë ¨
        if any(word in question_lower for word in ['ì…”í‹€', 'ë²„ìŠ¤', 'êµí†µ', 'ì‹œê°„í‘œ', 'ìš´í–‰', 'í†µí•™', 'ëŒ€ì „ì—­', 'ìœ ì„±']):
            relevant_info.append(("ì…”í‹€ë²„ìŠ¤_ì •ë³´", self.static_knowledge["shuttle"]))

        # ì—°ë½ì²˜ ì •ë³´ (í•­ìƒ í¬í•¨)
        relevant_info.append(("ì—°ë½ì²˜_ì •ë³´", self.static_knowledge["contacts"]))

        return relevant_info


class CompleteCampusChatBot:
    """ì™„ì „í•œ ìº í¼ìŠ¤ ì±—ë´‡ - AWQ ì–‘ìí™” ëª¨ë¸ ì‚¬ìš©"""

    def __init__(self, model_name = "Qwen/Qwen3-14B-AWQ"):
        self.model_name = model_name
        self.device = "cuda" if torch.cuda.is_available() else "cpu"

        print(f"ğŸ–¥ï¸ ë””ë°”ì´ìŠ¤: {self.device}")
        print(f"ğŸ¤– ëª¨ë¸: {model_name}")
        print("ğŸ”§ AWQ 4-bit ì–‘ìí™” ëª¨ë¸ ì‚¬ìš©")

        # ì™„ì „í•œ ì§€ì‹ ë² ì´ìŠ¤ ì´ˆê¸°í™”
        self.knowledge_base = CompleteCampusKnowledgeBase()
        print("ğŸ“š ì™„ì „í•œ ì§€ì‹ ë² ì´ìŠ¤ ë¡œë“œ ì™„ë£Œ")

        # ëª¨ë¸ ë¡œë“œ
        self.load_model()
        print("ğŸ¤– AWQ ì±—ë´‡ ì´ˆê¸°í™” ì™„ë£Œ")

    def load_model(self):
        """AWQ ì–‘ìí™” ëª¨ë¸ ë¡œë“œ"""
        try:
            print("ğŸ”„ AWQ ì–‘ìí™” Qwen ëª¨ë¸ ë¡œë”© ì¤‘...")

            # í† í¬ë‚˜ì´ì € ë¡œë“œ
            self.tokenizer = AutoTokenizer.from_pretrained(
                self.model_name,
                trust_remote_code=True
            )

            # pad_token ì„¤ì •
            if self.tokenizer.pad_token is None:
                self.tokenizer.pad_token = self.tokenizer.eos_token

            # AWQ ëª¨ë¸ ë¡œë“œ (ì´ë¯¸ ì–‘ìí™”ë˜ì–´ ìˆìŒ)
            self.model = AutoModelForCausalLM.from_pretrained(
                self.model_name,
                device_map="auto",
                torch_dtype=torch.float16,
                trust_remote_code=True,
                low_cpu_mem_usage=True
            )

            self.model.eval()
            print("âœ… AWQ ëª¨ë¸ ë¡œë”© ì™„ë£Œ (ë©”ëª¨ë¦¬ ì ˆì•½: ~70%)")

        except Exception as e:
            print(f"âŒ AWQ ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
            print("ğŸ’¡ AWQ ëª¨ë¸ì´ ì—†ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì¼ë°˜ ëª¨ë¸ë¡œ fallback ì‹œë„...")

            # Fallback to regular model
            try:
                fallback_model = "Qwen/Qwen2.5-7B-Instruct"
                print(f"ğŸ”„ {fallback_model}ë¡œ fallback ì‹œë„...")

                self.tokenizer = AutoTokenizer.from_pretrained(fallback_model, trust_remote_code=True)
                if self.tokenizer.pad_token is None:
                    self.tokenizer.pad_token = self.tokenizer.eos_token

                self.model = AutoModelForCausalLM.from_pretrained(
                    fallback_model,
                    device_map="auto",
                    torch_dtype=torch.float16,
                    trust_remote_code=True
                )

                self.model_name = fallback_model
                print("âœ… Fallback ëª¨ë¸ ë¡œë”© ì™„ë£Œ")

            except Exception as fallback_error:
                print(f"âŒ Fallback ëª¨ë¸ë„ ì‹¤íŒ¨: {fallback_error}")
                raise

    def create_rich_context(self, relevant_info):
        """í’ë¶€í•œ ì»¨í…ìŠ¤íŠ¸ ìƒì„± (ê¸¸ì´ ìµœì í™”)"""
        context = "=== ì¶©ë‚¨ëŒ€í•™êµ ì¢…í•© ì •ë³´ ===\n\n"

        for info_type, info_data in relevant_info:
            context += f"ã€{info_type}ã€‘\n"

            if info_type == "ìµœì‹ ê³µì§€" and isinstance(info_data, list):
                for i, notice in enumerate(info_data[:2], 1):  # 3ê°œ â†’ 2ê°œë¡œ ì¶•ì†Œ
                    context += f"{i}. {notice.get('title', 'N/A')}\n"

            elif info_type == "ì˜¤ëŠ˜ë©”ë‰´":
                if info_data.get('status') == "í¬ë¡¤ë§ ì„±ê³µ":
                    context += f"ë‚ ì§œ: {info_data['date']} ({info_data['day']}ìš”ì¼)\n"
                    if 'items' in info_data and info_data['items']:
                        context += f"ë©”ë‰´: {', '.join(info_data['items'][:3])}\n"  # 5ê°œ â†’ 3ê°œë¡œ ì¶•ì†Œ
                else:
                    context += f"ìƒíƒœ: {info_data.get('message', 'ì •ë³´ ì—†ìŒ')}\n"

            elif isinstance(info_data, dict):
                # í•µì‹¬ ì •ë³´ë§Œ í¬í•¨í•˜ë„ë¡ ì¶•ì†Œ
                key_count = 0
                for key, value in info_data.items():
                    if key_count >= 3:  # ìµœëŒ€ 3ê°œ í•­ëª©ë§Œ
                        break
                    if isinstance(value, dict):
                        context += f"â€¢ {key}: {str(value)[:50]}...\n"  # ê¸¸ì´ ì œí•œ
                    else:
                        context += f"â€¢ {key}: {str(value)[:100]}\n"  # ê¸¸ì´ ì œí•œ
                    key_count += 1

            context += "\n"

            # ì „ì²´ ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´ ì œí•œ
            if len(context) > 1500:  # ê¸¸ì´ ì œí•œ ê°•í™”
                context = context[:1500] + "...\n"
                break

        return context

    def create_balanced_prompt(self, question, context):
        """ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        now = datetime.now()
        today = date.today()
        weekday = today.strftime('%A')

        # ê°„ë‹¨í•œ ì‹œê°„ ì •ë³´ë§Œ
        current_context = f"í˜„ì¬: {now.strftime('%Y-%m-%d %H:%M')} ({weekday})"

        prompt = f"""/no_think <|im_start|>system
                ë‹¹ì‹ ì€ ì¶©ë‚¨ëŒ€í•™êµ í•™ìƒ ë„ìš°ë¯¸ì…ë‹ˆë‹¤. 
                ë‹¤ìŒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê°„ê²°í•˜ê³  ì •í™•í•œ ë‹µë³€ì„ í•´ì£¼ì„¸ìš”.
                {current_context}
                {context}
                <|im_end|>
                <|im_start|>user
                {question}
                <|im_end|>
                <|im_start|>assistant
                """
        return prompt

    def extract_answer_from_response(self, full_response, prompt):
        """ì‘ë‹µì—ì„œ ì‹¤ì œ ë‹µë³€ ë¶€ë¶„ë§Œ ì¶”ì¶œ - ê°„ì†Œí™”ëœ ë²„ì „"""
        try:
            # 1. í”„ë¡¬í”„íŠ¸ ë¶€ë¶„ ì œê±°
            if full_response.startswith(prompt):
                answer = full_response[len(prompt):].strip()
            else:
                # 2. assistant í† í° ì´í›„ ë¶€ë¶„ ì¶”ì¶œ
                if "<|im_start|>assistant" in full_response:
                    parts = full_response.split("<|im_start|>assistant")
                    answer = parts[-1].strip()
                else:
                    answer = full_response.strip()

            # 3. íŠ¹ìˆ˜ í† í°ë“¤ ì œê±°
            answer = re.sub(r'<\|im_end\|>', '', answer)
            answer = re.sub(r'<\|im_start\|>.*?>', '', answer)

            # 4. ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ê°€ ë‹µë³€ì— í¬í•¨ëœ ê²½ìš° ì œê±°
            if "ë‹¹ì‹ ì€ ì¶©ë‚¨ëŒ€í•™êµ í•™ìƒ ë„ìš°ë¯¸ì…ë‹ˆë‹¤" in answer:
                parts = answer.split("assistant")
                if len(parts) > 1:
                    answer = parts[-1].strip()

            # 5. ì»¨í…ìŠ¤íŠ¸ ì •ë³´ê°€ ë‹µë³€ì— í¬í•¨ëœ ê²½ìš° ì œê±°
            if "=== ì¶©ë‚¨ëŒ€í•™êµ ì¢…í•© ì •ë³´ ===" in answer:
                parts = answer.split("ê°„ê²°í•˜ê³  ì •í™•í•œ ë‹µë³€ì„ í•´ì£¼ì„¸ìš”.")
                if len(parts) > 1:
                    answer = parts[-1].strip()

            # 6. ì—­í•  íƒœê·¸ë“¤ ì œê±°
            answer = re.sub(r'^(system|user|assistant)\s*', '', answer)
            answer = re.sub(r'\n(system|user|assistant)\s*', '\n', answer)

            # 7. ì•ë’¤ ê³µë°± ë° ê°œí–‰ ì •ë¦¬
            answer = answer.strip()

            # 8. ë¹ˆ ë‹µë³€ì´ë©´ None ë°˜í™˜
            if not answer or len(answer.strip()) < 3:
                return None

            return answer

        except Exception as e:
            print(f"âš ï¸ ë‹µë³€ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {e}")
            return None


    def generate_comprehensive_answer(self, question, max_new_tokens=30000):
        """ë©”ëª¨ë¦¬ ìµœì í™”ëœ ë‹µë³€ ìƒì„±"""
        try:
            print(f"ğŸ” ì§ˆë¬¸ ë¶„ì„ ì¤‘: {question}")

            # ë©”ëª¨ë¦¬ ì •ë¦¬
            if torch.cuda.is_available():
                torch.cuda.empty_cache()

            # 1. ê´€ë ¨ ì •ë³´ ê²€ìƒ‰
            relevant_info = self.knowledge_base.search_comprehensive_info(question)

            # 2. ì»¨í…ìŠ¤íŠ¸ ìƒì„± (í¬ê¸° ì œí•œ)
            context = self.create_rich_context(relevant_info)

            # 3. í”„ë¡¬í”„íŠ¸ ìƒì„±
            prompt = self.create_balanced_prompt(question, context)

            # 4. í† í¬ë‚˜ì´ì§• (ê¸¸ì´ ì œí•œ ê°•í™”)
            inputs = self.tokenizer(
                prompt,
                return_tensors="pt",
                truncation=True,
                max_length=3000  # ë” ì§§ê²Œ ì œí•œ
            ).to(self.device)

            # ë©”ëª¨ë¦¬ ì •ë¦¬
            if torch.cuda.is_available():
                torch.cuda.empty_cache()

            # 5. ë‹µë³€ ìƒì„± (ë©”ëª¨ë¦¬ ì ˆì•½ ì„¤ì •)
            with torch.no_grad():
                outputs = self.model.generate(
                    **inputs,
                    max_new_tokens=max_new_tokens,  # ë” ì§§ê²Œ ì œí•œ
                    do_sample=True,
                    temperature=0.7,
                    pad_token_id=self.tokenizer.eos_token_id,
                    eos_token_id=self.tokenizer.eos_token_id
                )

            # ì¦‰ì‹œ ë©”ëª¨ë¦¬ í•´ì œ
            del inputs
            if torch.cuda.is_available():
                torch.cuda.empty_cache()

            # 6. ë””ì½”ë”©
            full_response = self.tokenizer.decode(outputs[0], skip_special_tokens=True).strip()

            # ë©”ëª¨ë¦¬ í•´ì œ
            del outputs
            if torch.cuda.is_available():
                torch.cuda.empty_cache()

            # 7. ë‹µë³€ ì¶”ì¶œ (í”„ë¡¬í”„íŠ¸ì™€ íŠ¹ìˆ˜ í† í° ì œê±°)
            answer = self.extract_answer_from_response(full_response, prompt)

            # 8. ë‹µë³€ í’ˆì§ˆ ê²€ì‚¬
            if not answer or len(answer) < 5:
                return self.get_fallback_answer(question)

            print("âœ… ë‹µë³€ ìƒì„± ì™„ë£Œ")
            return answer

        except torch.cuda.OutOfMemoryError:
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
            print("âŒ GPU ë©”ëª¨ë¦¬ ë¶€ì¡± - Fallback ì‚¬ìš©")
            return self.get_fallback_answer(question)

        except Exception as e:
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
            print(f"âŒ ë‹µë³€ ìƒì„± ì˜¤ë¥˜: {e}")
            return self.get_fallback_answer(question)

    def get_fallback_answer(self, question):
        """ê°„ë‹¨í•œ Fallback ë‹µë³€ (ë©”ëª¨ë¦¬ ì ˆì•½)"""
        question_lower = question.lower()

        if any(word in question_lower for word in ['ì…”í‹€', 'ë²„ìŠ¤']):
            return """ğŸšŒ 2025ë…„ ì¶©ë‚¨ëŒ€ ì…”í‹€ë²„ìŠ¤ ì•ˆë‚´

ğŸ“ êµë‚´ìˆœí™˜: 08:30~17:30 (1ì¼ 10íšŒ)
ì‹œê°„: 08:30, 09:30, 09:40, 10:30, 11:30, 13:30, 14:30, 15:30, 16:30, 17:30

ğŸ“ ë“±êµì „ìš©: ì›”í‰ì—­ 08:20 ì¶œë°œ â†’ ì •ì‹¬í™” êµ­ì œë¬¸í™”íšŒê´€
ğŸ“ ìº í¼ìŠ¤ìˆœí™˜: 08:10 ëŒ€ë• ì¶œë°œ â†’ 08:50 ë³´ìš´ ë„ì°©

ğŸ“ ë¬¸ì˜: ì´ë¬´ê³¼ 042-821-5114"""

        elif any(word in question_lower for word in ['ì¡¸ì—…', 'í•™ì ']):
            return "ì¶©ë‚¨ëŒ€í•™êµ ì¡¸ì—…ìš”ê±´ì€ 130í•™ì  ì´ìƒì…ë‹ˆë‹¤. ê³µí•™ê³„ì—´ì€ 140í•™ì ì´ í•„ìš”í•©ë‹ˆë‹¤. ìì„¸í•œ ë¬¸ì˜: í•™ì‚¬ì§€ì›ê³¼ 042-821-5025"

        elif any(word in question_lower for word in ['ì‹ë‹¨', 'ë©”ë‰´']):
            return "í•™ìƒì‹ë‹¹: í•œì‹ 4,000ì›, ì–‘ì‹ 5,000ì›. ìš´ì˜ì‹œê°„: 11:30-14:00, 17:30-19:00. ìƒí˜‘: 042-821-5890"

        else:
            return "ë¬¸ì˜ì‚¬í•­ì€ ê´€ë ¨ ë¶€ì„œë¡œ ì—°ë½ì£¼ì„¸ìš”. í•™ì‚¬ì§€ì›ê³¼ 042-821-5025, ì´ë¬´ê³¼ 042-821-5114"

    def process_test_file(self, test_file_path, output_file_path):
        """ê°œë³„ ì²˜ë¦¬ë¡œ ë©”ëª¨ë¦¬ ì ˆì•½"""
        try:
            if not os.path.exists(test_file_path):
                print(f"âŒ í…ŒìŠ¤íŠ¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {test_file_path}")
                return False

            with open(test_file_path, 'r', encoding='utf-8') as f:
                test_data = json.load(f)

            results = []
            print(f"ğŸ“ AWQ ëª¨ë¸ ê°œë³„ ì²˜ë¦¬ ì¤‘... (ì´ {len(test_data)}ê°œ)")

            for i, item in enumerate(test_data):
                try:
                    print(f"ğŸ”„ {i+1}/{len(test_data)}: {item['user'][:30]}...")

                    # ê° ì§ˆë¬¸ë§ˆë‹¤ ë©”ëª¨ë¦¬ ì •ë¦¬
                    if torch.cuda.is_available():
                        torch.cuda.empty_cache()

                    answer = self.generate_comprehensive_answer(item['user'])

                    results.append({
                        "user": item['user'],
                        "model": answer
                    })

                    # 5ê°œë§ˆë‹¤ ì¤‘ê°„ ì €ì¥ ë° ë©”ëª¨ë¦¬ ì •ë¦¬
                    if (i + 1) % 3 == 0:
                        print(f"ğŸ’¾ ì¤‘ê°„ ì €ì¥... ({i+1}ê°œ ì™„ë£Œ)")
                        self.save_partial_results(results, output_file_path)
                        if torch.cuda.is_available():
                            torch.cuda.empty_cache()

                except Exception as e:
                    print(f"âŒ ì§ˆë¬¸ {i+1} ì‹¤íŒ¨: {e}")
                    results.append({
                        "user": item['user'],
                        "model": f"ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}"
                    })
                    if torch.cuda.is_available():
                        torch.cuda.empty_cache()

            # ìµœì¢… ì €ì¥
            os.makedirs(os.path.dirname(output_file_path), exist_ok=True)
            with open(output_file_path, 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2)

            print(f"âœ… AWQ ëª¨ë¸ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {output_file_path}")
            return True

        except Exception as e:
            print(f"âŒ í…ŒìŠ¤íŠ¸ íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            return False

    def save_partial_results(self, results, output_file_path):
        """ë¶€ë¶„ ê²°ê³¼ ì €ì¥"""
        try:
            os.makedirs(os.path.dirname(output_file_path), exist_ok=True)
            with open(output_file_path, 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"âš ï¸ ì¤‘ê°„ ì €ì¥ ì‹¤íŒ¨: {e}")

    def chat_interactive(self):
        """ëŒ€í™”í˜• ì±„íŒ…"""
        print("\nğŸ¤– ì¶©ë‚¨ëŒ€ AWQ ì–‘ìí™” RAG ì±—ë´‡ì…ë‹ˆë‹¤!")
        print("ğŸ“¡ ì‹¤ì‹œê°„ ì •ë³´ í¬ë¡¤ë§ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
        print("(ì¢…ë£Œ: 'quit' ë˜ëŠ” 'exit')")

        while True:
            try:
                user_input = input("\nğŸ‘¤ ì§ˆë¬¸: ").strip()

                if user_input.lower() in ['quit', 'exit', 'ì¢…ë£Œ']:
                    print("ğŸ‘‹ ì´ìš©í•´ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤!")
                    break

                if not user_input:
                    continue

                print("ğŸ” ì •ë³´ ê²€ìƒ‰ ë° ë‹µë³€ ìƒì„± ì¤‘...")
                answer = self.generate_comprehensive_answer(user_input)
                print(f"ğŸ¤– ë‹µë³€: {answer}")

            except KeyboardInterrupt:
                print("\nğŸ‘‹ ì´ìš©í•´ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤!")
                break


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸ“ ì¶©ë‚¨ëŒ€ Campus RAG ChatBot (AWQ ì–‘ìí™”)")
    print("ğŸ“¡ ì‹¤ì‹œê°„ í¬ë¡¤ë§ + ì •ì  ì •ë³´ + AWQ 4-bit ì–‘ìí™”")
    print("ğŸ”§ ë©”ëª¨ë¦¬ ìµœì í™” ë²„ì „")
    print("=" * 60)

    try:
        # AWQ ì–‘ìí™” RAG ì±—ë´‡ ì´ˆê¸°í™”
        chatbot = CompleteCampusChatBot(
            model_name = "Qwen/Qwen3-14B-AWQ"
        )

        # í…ŒìŠ¤íŠ¸ íŒŒì¼ ì²˜ë¦¬
        test_file_path = "./data/shuttle_test_chat.json"
        output_file_path = "./outputs/think_shuttle_test_chat_output.json"

        if os.path.exists(test_file_path):
            print(f"ğŸ“‚ í…ŒìŠ¤íŠ¸ íŒŒì¼ ë°œê²¬: {test_file_path}")
            success = chatbot.process_test_file(test_file_path, output_file_path)

            if success:
                print("âœ… AWQ ì–‘ìí™” ì±—ë´‡ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")

                # ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°
                with open(output_file_path, 'r', encoding='utf-8') as f:
                    results = json.load(f)

                print("\nğŸ“‹ ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸° (ì²˜ìŒ 3ê°œ):")
                for i, result in enumerate(results[:3]):
                    print(f"\n{i + 1}. ì§ˆë¬¸: {result['user']}")
                    print(f"   ë‹µë³€: {result['model']}")
                    print("-" * 60)

                # ëª¨ë¸ ì •ë³´ ì¶œë ¥
                print(f"\nğŸ¤– ì‚¬ìš©ëœ ëª¨ë¸: {chatbot.model_name}")
                print(f"ğŸ”§ ì–‘ìí™”: AWQ 4-bit")
                print(f"ğŸ–¥ï¸ ì‹¤í–‰ ë””ë°”ì´ìŠ¤: {chatbot.device}")
                print(f"ğŸ’¾ ì˜ˆìƒ ë©”ëª¨ë¦¬ ì ˆì•½: 70%")

            else:
                print("âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨!")
        else:
            print(f"âš ï¸ í…ŒìŠ¤íŠ¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {test_file_path}")
            print("ëŒ€í™”í˜• ëª¨ë“œë¡œ ì „í™˜í•©ë‹ˆë‹¤.")

            # ëŒ€í™”í˜• í…ŒìŠ¤íŠ¸
            sample_questions = [
                "ì…”í‹€ë²„ìŠ¤ ì‹œê°„í‘œë¥¼ ì•Œë ¤ì£¼ì„¸ìš”",
                "ì›”í‰ì—­ì—ì„œ í•™êµê¹Œì§€ ì…”í‹€ë²„ìŠ¤ ìˆë‚˜ìš”?",
                "ì¡¸ì—…ê¹Œì§€ ëª‡ í•™ì ì´ í•„ìš”í•œê°€ìš”?",
                "ì˜¤ëŠ˜ í•™ì‹ ë©”ë‰´ê°€ ë­”ê°€ìš”?"
            ]

            print("\nğŸ§ª ìƒ˜í”Œ ì§ˆë¬¸ìœ¼ë¡œ í…ŒìŠ¤íŠ¸:")
            for i, question in enumerate(sample_questions):
                print(f"\nğŸ¤– ì§ˆë¬¸ {i + 1}: {question}")
                answer = chatbot.generate_comprehensive_answer(question)
                print(f"ğŸ“ ë‹µë³€: {answer}")
                print("-" * 60)

    except Exception as e:
        print(f"âŒ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        print("ğŸ’¡ AWQ ëª¨ë¸ì´ ì—†ê±°ë‚˜ GPU ë©”ëª¨ë¦¬ ë¶€ì¡±ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤")
        print("ğŸ’¡ fallback ëª¨ë¸ë¡œ ìë™ ì „í™˜ë©ë‹ˆë‹¤")


if __name__ == "__main__":
    main()